{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feced6b7-d875-494c-9164-4336e1ab6789",
   "metadata": {},
   "source": [
    "\r\n",
    "\r\n",
    "| **Category**              | **Model**                                                                                      | **Description**                                                                                                        |\r\n",
    "|---------------------------|------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------|\r\n",
    "| **Image Classification**  | LeNet-5                                                                                        | One of the earliest convolutional neural networks, designed for handwritten digit recognition in the MNIST dataset.    |\r\n",
    "|                           | VGG16                                                                                          | Known for its simplicity and uniform architecture, it has 16 layers and is commonly used in image classification tasks.|\r\n",
    "|                           | ResNet-50                                                                                      | Utilizes residual connections to ease the training of very deep networks, contains 50 layers.                          |\r\n",
    "|                           | InceptionV3                                                                                    | Known for its \"Inception\" modules that allow for more efficient computation, this model has 48 layers.                 |\r\n",
    "|                           | AlexNet                                                                                        | Consists of 8 layers and won the ImageNet Large Scale Visual Recognition Challenge in 2012, popularizing deep learning for image recognition. |\r\n",
    "|                           | DenseNet                                                                                       | Connects each layer to every other layer in a feed-forward fashion, improves efficiency and reduces the vanishing gradient problem. |\r\n",
    "|                           | MobileNet                                                                                      | Optimized for mobile and embedded vision applications, known for being lightweight and efficient.                      |\r\n",
    "|                           | EfficientNet                                                                                   | Uses neural architecture search to create a family of models that scale efficiently and achieve state-of-the-art accuracy. |\r\n",
    "| **Object Detection**      | YOLO (You Only Look Once)                                                                      | Real-time object detection system that frames object detection as a single regression problem, making it extremely fast.|\r\n",
    "|                           | Faster R-CNN (Region-Based Convolutional Neural Network)                                       | Combines the region proposal network (RPN) with Fast R-CNN, achieving high detection accuracy.                          |\r\n",
    "|                           | SSD (Single Shot MultiBox Detector)                                                            | Provides a fast and efficient object detection system by discretizing the output space of bounding boxes into a set of default boxes. |\r\n",
    "|                           | Mask R-CNN                                                                                     | An extension of Faster R-CNN that also performs pixel-level segmentation in addition to object detection.               |\r\n",
    "|                           | RetinaNet                                                                                      | Introduces the Focal Loss to handle the class imbalance problem and performs well on object detection tasks.            |\r\n",
    "| **Natural Language Processing (NLP)** | BERT (Bidirectional Encoder Representations from Transformers) | Pre-trained on large text corpora and fine-tuned for various NLP tasks such as question answering and sentiment analysis. |\r\n",
    "|                           | GPT-3 (Generative Pre-trained Transformer 3)                                                   | One of the largest language models, capable of generating coherent and contextually relevant text, used for tasks such as text completion and language translation. |\r\n",
    "|                           | RoBERTa (Robustly optimized BERT approach)                                                     | A variant of BERT with improved training techniques for better performance on NLP tasks.                                |\r\n",
    "|                           | T5 (Text-To-Text Transfer Transformer)                                                         | Converts every NLP problem into a text-to-text format, allowing the same model to be used for multiple tasks.           |\r\n",
    "|                           | XLNet                                                                                          | An autoregressive language model that captures bidirectional context by maximizing the expected likelihood over all permutations of the factorization order. |\r\n",
    "| **Semantic Segmentation** | U-Net                                                                                          | Originally designed for biomedical image segmentation, known for its U-shaped architecture which enables precise segmentation.|\r\n",
    "|                           | DeepLab                                                                                       | Uses atrous convolution to extract dense feature maps for precise segmentation.                                        |\r\n",
    "| **Generative Models**     | GANs (Generative Adversarial Networks)                                                        | Consists of two neural networks, a generator, and a discriminator, pitting them against each other to generate realistic data.|\r\n",
    "|                           | VAEs (Variational Autoencoders)                                                                | Used for generating new data points by learning the underlying distribution of the input data.                         |\r\n",
    "|                           | StyleGAN                                                                                       | Generates high-quality images with fine-grained control over the style of the generated images.                        |\r\n",
    "|                           | PixelCNN                                                                                       | Uses a probabilistic model to generate images one pixel at a time, based on the context of preer details, feel free to ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8859f5c7-b8db-4e7e-a2fd-43b4604fe1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
