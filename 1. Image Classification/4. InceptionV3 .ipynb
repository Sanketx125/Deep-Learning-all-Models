{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2afa19b-17d6-4a5d-bc83-46748e00d6f3",
   "metadata": {},
   "source": [
    "## InceptionV3 Model:\n",
    "\n",
    "---\n",
    "Developed by: Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich\n",
    "\n",
    "Published in: 2015\n",
    "\n",
    "Primary Use Case: Image classification\n",
    "\n",
    "---\n",
    "### Architecture:\n",
    "Input Layer: 299x299 RGB images\n",
    "\n",
    "Initial Convolution and Pooling:\n",
    "\n",
    "3x3 convolution with 32 filters, stride 2\n",
    "\n",
    "3x3 convolution with 32 filters\n",
    "\n",
    "3x3 convolution with 64 filters, padding 1\n",
    "\n",
    "3x3 max pooling with stride 2\n",
    "\n",
    "1x1 convolution with 80 filters\n",
    "\n",
    "3x3 convolution with 192 filters\n",
    "\n",
    "3x3 max pooling with stride 2\n",
    "\n",
    "Inception Modules:\n",
    "\n",
    "1st Inception Module: Combination of 1x1, 3x3, 5x5 convolutions, and 3x3 max pooling\n",
    "\n",
    "2nd Inception Module: Same structure as the 1st Inception Module with different filter sizes\n",
    "\n",
    "Global Average Pooling: Converts feature maps into a 1D feature vector\n",
    "\n",
    "Fully Connected Layer: Number of classes (usually 1000 for ImageNet)\n",
    "\n",
    "Dropout: Applied before the fully connected layer to prevent overfitting\n",
    "\n",
    "Activation Functions: Uses ReLU activation function after each convolutional layer\n",
    "\n",
    "---\n",
    "### Key Features:\n",
    "Inception Modules: Combines multiple convolutional filters of different sizes to capture various features at different scales.\n",
    "\n",
    "Factorized Convolutions: Efficient computation by factorizing convolutions into smaller operations (e.g., 3x3 into two 1x3 and 3x1 convolutions).\n",
    "\n",
    "High Performance: Achieved state-of-the-art results on the ImageNet dataset at the time of its release.\n",
    "\n",
    "---\n",
    "### Applications:\n",
    "Image Classification: Used for classifying images into different categories.\n",
    "\n",
    "Feature Extraction: Pre-trained InceptionV3 models are often used to extract features from images for transfer learning in other tasks.\n",
    "\n",
    "---\n",
    "### Impact:\n",
    "Influence: InceptionV3 has influenced the design of many subsequent deep learning models with its innovative inception modules.\n",
    "\n",
    "Benchmark: Often used as a benchmark for comparing the performance of new models and techniques in the field of computer vision.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49bf32f5-7b43-4c54-bbae-98e75883e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out1x1, out3x3red, out3x3, out5x5red, out5x5, out_pool):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        \n",
    "        self.branch1 = nn.Conv2d(in_channels, out1x1, kernel_size=1)\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out3x3red, kernel_size=1),\n",
    "            nn.Conv2d(out3x3red, out3x3, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out5x5red, kernel_size=1),\n",
    "            nn.Conv2d(out5x5red, out5x5, kernel_size=5, padding=2)\n",
    "        )\n",
    "\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels, out_pool, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "        outputs = [branch1, branch2, branch3, branch4]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class InceptionV3(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(InceptionV3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(64, 80, kernel_size=1)\n",
    "        self.conv5 = nn.Conv2d(80, 192, kernel_size=3)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        self.inception1 = InceptionModule(192, 64, 48, 64, 64, 96, 32)\n",
    "        self.inception2 = InceptionModule(256, 64, 48, 64, 64, 96, 64)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(288, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.inception1(x)\n",
    "        x = self.inception2(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3ae9a1-ad1b-46d5-83f8-c8e066a72d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the InceptionV3 model\n",
    "model = InceptionV3(num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe1440e5-b8e2-43cd-ae80-0bed5b593df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionV3(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv5): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (inception1): InceptionModule(\n",
       "    (branch1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch2): Sequential(\n",
       "      (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(64, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (inception2): InceptionModule(\n",
       "    (branch1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch2): Sequential(\n",
       "      (0): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(64, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=288, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678fa359-73a8-460c-a32a-75de208b6630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
